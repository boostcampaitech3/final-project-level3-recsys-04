{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 임베딩 유사도 기반 추천 리스트를 DB에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "# NLP\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Download\n",
    "from requests import get\n",
    "\n",
    "# Crawling\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 NLP 전처리\n",
    "def data_text_cleaning(data):\n",
    " \n",
    "    # 영문자 이외 문자는 공백으로 변환\n",
    "    only_english = re.sub('[^a-zA-Z]', ' ', data)\n",
    " \n",
    "    # 소문자 변환\n",
    "    no_capitals = only_english.lower().split()\n",
    " \n",
    "    # 불용어 제거\n",
    "    stops = set(stopwords.words('english'))\n",
    "    no_stops = [word for word in no_capitals if not word in stops]\n",
    " \n",
    "    # 어간 추출\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    stemmer_words = [stemmer.stem(word) for word in no_stops]\n",
    " \n",
    "    # 공백으로 구분된 문자열로 결합하여 결과 반환\n",
    "    return stemmer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 접속\n",
    "client = MongoClient(\"###\")\n",
    "db = client['final_project']\n",
    "similarity = db['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확보\n",
    "result = list(db.repository.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2698/2698 [00:00<00:00, 467825.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# repo url 확보\n",
    "base = 'https://github.com/'\n",
    "links = []\n",
    "link2rid = {}\n",
    "for r in tqdm(result):\n",
    "    link = base + r['login'] + '/' + r['repo_name']\n",
    "    links.append(link)\n",
    "    link2rid[link] = r['rid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2698 [00:00<?, ?it/s]/var/folders/2r/84h7vtf95y92s6tnl1ngwhdh0000gn/T/ipykernel_15788/2339693427.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path,chrome_options=options)\n",
      "/var/folders/2r/84h7vtf95y92s6tnl1ngwhdh0000gn/T/ipykernel_15788/2339693427.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path,chrome_options=options)\n",
      "100%|██████████| 2698/2698 [2:14:01<00:00,  2.98s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Repo마다 Readme, about, tag 크롤링\n",
    "readme_dic = {}\n",
    "about_dic = {}\n",
    "tag_dic = {}\n",
    "doc_dic = {}\n",
    "for link in tqdm(links):\n",
    "    try:\n",
    "        driver_path = '/Users/pilkyu/Driver/chromedriver'\n",
    "        url = link\n",
    "        driver = webdriver.Chrome(executable_path=driver_path,chrome_options=options)\n",
    "        driver.get(url)\n",
    "        source = driver.page_source\n",
    "        bs = bs4.BeautifulSoup(source,'lxml')\n",
    "        readme = bs.find('article','markdown-body entry-content container-lg')\n",
    "        readme = readme.get_text().replace('\\n','').replace('\\xa0','')\n",
    "        about = bs.find('p','f4 my-3')\n",
    "        about = about.get_text().replace('\\n','')   \n",
    "        tag = bs.find_all('a','topic-tag topic-tag-link')\n",
    "        tag = ''.join([t.get_text() for t in tag]).replace('\\n','')\n",
    "        readme_dic[link2rid[link]] = readme\n",
    "        about_dic[link2rid[link]] = about\n",
    "        tag_dic[link2rid[link]] = tag\n",
    "        doc_dic[link2rid[link]] = tag_dic[link2rid[link]] + ' ' + about_dic[link2rid[link]] + ' ' + readme_dic[link2rid[link]]\n",
    "        doc_dic[link2rid[link]] = data_text_cleaning(doc_dic[link2rid[link]])\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피클로 저장\n",
    "pd.to_pickle(readme_dic, 'readme_dic.pkl')\n",
    "pd.to_pickle(about_dic, 'about_dic.pkl')\n",
    "pd.to_pickle(tag_dic, 'tag_dic.pkl')\n",
    "pd.to_pickle(doc_dic, 'doc_dic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dic = pd.read_pickle('doc_dic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus_list = [TaggedDocument(tags=[str(key)], words=value) for key, value in zip(doc_dic.keys(),doc_dic.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1,vector_size=100)\n",
    "\n",
    "# Vocabulary 빌드\n",
    "model.build_vocab(tagged_corpus_list)\n",
    "\n",
    "# Doc2Vec 학습\n",
    "model.train(tagged_corpus_list, total_examples=model.corpus_count, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2658/2658 [00:00<00:00, 2794.19it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_sim = {}\n",
    "for rid in tqdm(doc_dic.keys()):\n",
    "    doc_sim[rid] = [int(rid[0]) for rid in model.docvecs.most_similar(str(rid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2658/2658 [00:00<00:00, 254525.24it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_list = []\n",
    "for rid, doc_sim_list in tqdm(doc_sim.items()):\n",
    "    temp_dic = {}\n",
    "    temp_dic['rid'] = rid\n",
    "    temp_dic['doc_sim'] = doc_sim_list\n",
    "    sim_list.append(temp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.insert_many(sim_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "605e7643abd9dfc7616fd6f04112a644752ada8d5520b8f4933a2d4a6a0355fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
